<!DOCTYPE html>
<html lang="zh-CN">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>MiniCPM-o 4.5</title>
<style>
/* ========== Variables ========== */
:root {
  --bg: #0c0c1d;
  --bg-card: rgba(22, 22, 42, 0.85);
  --bg-card-hover: rgba(30, 30, 55, 0.9);
  --accent: #7c6cf0;
  --accent-glow: rgba(124, 108, 240, 0.35);
  --accent-light: #a78bfa;
  --text: #e2e8f0;
  --text-muted: #8892a8;
  --success: #22c55e;
  --warning: #f59e0b;
  --error: #ef4444;
  --border: rgba(255,255,255,0.08);
  --radius: 14px;
}

/* ========== Reset & Base ========== */
*{margin:0;padding:0;box-sizing:border-box}
html,body{height:100%}
body{
  font-family:-apple-system,BlinkMacSystemFont,'Segoe UI',Roboto,'Helvetica Neue',sans-serif;
  background:var(--bg);
  color:var(--text);
  overflow:hidden;
}

/* ========== App Shell ========== */
.app{
  max-width:720px;
  margin:0 auto;
  height:100vh;
  display:flex;
  flex-direction:column;
  padding:16px 16px 0;
}

/* ========== Header ========== */
.header{
  text-align:center;
  padding:12px 0 8px;
  flex-shrink:0;
}
.header h1{
  font-size:22px;
  font-weight:700;
  background:linear-gradient(135deg,#a78bfa,#6366f1);
  -webkit-background-clip:text;
  -webkit-text-fill-color:transparent;
  letter-spacing:-0.5px;
}
.header p{
  font-size:12px;
  color:var(--text-muted);
  margin-top:2px;
}

/* ========== Mode Tabs ========== */
.mode-tabs{
  display:flex;
  gap:6px;
  padding:8px 0;
  flex-shrink:0;
}
.mode-tab{
  flex:1;
  padding:10px 0;
  border:1px solid var(--border);
  border-radius:10px;
  background:transparent;
  color:var(--text-muted);
  font-size:13px;
  font-weight:600;
  cursor:pointer;
  transition:all .2s;
  display:flex;
  align-items:center;
  justify-content:center;
  gap:6px;
}
.mode-tab:hover{background:var(--bg-card)}
.mode-tab.active{
  background:var(--bg-card);
  color:var(--text);
  border-color:var(--accent);
  box-shadow:0 0 12px var(--accent-glow);
}

/* ========== Content ========== */
.content{
  flex:1;
  display:flex;
  flex-direction:column;
  gap:10px;
  overflow:hidden;
  padding:6px 0;
}

/* ========== Video Panel ========== */
.video-panel{
  position:relative;
  background:var(--bg-card);
  border-radius:var(--radius);
  border:1px solid var(--border);
  overflow:hidden;
  flex-shrink:0;
  height:200px;
  display:flex;
  align-items:center;
  justify-content:center;
}
.video-panel.hidden{display:none}
.video-panel video{
  width:100%;
  height:100%;
  object-fit:cover;
}
.video-panel canvas{display:none}
.video-panel .avatar{
  width:100px;
  height:100px;
  border-radius:50%;
  background:linear-gradient(135deg,var(--accent),#8b5cf6);
  display:flex;
  align-items:center;
  justify-content:center;
  font-size:44px;
  position:relative;
}
.video-panel .avatar.speaking::after{
  content:'';
  position:absolute;
  inset:-12px;
  border-radius:50%;
  border:2px solid var(--accent-light);
  opacity:0;
  animation:ripple 1.5s ease-out infinite;
}
@keyframes ripple{
  0%{transform:scale(.8);opacity:.6}
  100%{transform:scale(1.4);opacity:0}
}

/* ========== Chat Panel ========== */
.chat-panel{
  flex:1;
  overflow-y:auto;
  background:var(--bg-card);
  border-radius:var(--radius);
  border:1px solid var(--border);
  padding:12px;
  display:flex;
  flex-direction:column;
  gap:10px;
  min-height:0;
}
.chat-panel::-webkit-scrollbar{width:4px}
.chat-panel::-webkit-scrollbar-thumb{background:var(--border);border-radius:2px}

.msg{display:flex;gap:8px;align-items:flex-start}
.msg.user{flex-direction:row-reverse}
.msg-bubble{
  max-width:78%;
  padding:10px 14px;
  border-radius:14px;
  font-size:14px;
  line-height:1.55;
  word-break:break-word;
}
.msg.assistant .msg-bubble{
  background:rgba(99,102,241,0.12);
  border:1px solid rgba(99,102,241,0.15);
  border-bottom-left-radius:4px;
}
.msg.user .msg-bubble{
  background:rgba(255,255,255,0.06);
  border:1px solid var(--border);
  border-bottom-right-radius:4px;
  color:var(--text-muted);
}
.msg.system .msg-bubble{
  background:transparent;
  color:var(--text-muted);
  font-size:12px;
  text-align:center;
  max-width:100%;
  padding:4px;
}
.msg-text-streaming{opacity:.85}
.msg-time{font-size:10px;color:var(--text-muted);margin-top:4px;opacity:.7}

/* ========== Controls ========== */
.controls{
  flex-shrink:0;
  padding:10px 0 20px;
  display:flex;
  flex-direction:column;
  gap:10px;
  align-items:center;
}

.status-bar{
  font-size:12px;
  color:var(--text-muted);
  padding:4px 14px;
  border-radius:20px;
  background:rgba(255,255,255,0.04);
  transition:all .2s;
}
.status-bar.ok{color:var(--success)}
.status-bar.warn{color:var(--warning)}
.status-bar.err{color:var(--error)}
.status-bar.active{color:var(--accent-light)}

.btn-row{
  display:flex;
  gap:12px;
  align-items:center;
}

/* Primary action button */
.action-btn{
  width:64px;height:64px;
  border-radius:50%;
  border:none;
  cursor:pointer;
  font-size:24px;
  display:flex;align-items:center;justify-content:center;
  transition:all .2s;
  position:relative;
}
.action-btn:disabled{opacity:.35;cursor:not-allowed}

.mic-btn{
  background:linear-gradient(135deg,#6366f1,#8b5cf6);
  color:white;
  box-shadow:0 4px 20px var(--accent-glow);
}
.mic-btn:hover:not(:disabled){transform:scale(1.08)}
.mic-btn:active:not(:disabled){transform:scale(.95)}
.mic-btn.recording{
  background:linear-gradient(135deg,#ef4444,#dc2626);
  box-shadow:0 4px 20px rgba(239,68,68,0.4);
  animation:pulse-rec 1.2s ease-in-out infinite;
}
@keyframes pulse-rec{
  0%,100%{box-shadow:0 4px 20px rgba(239,68,68,0.4)}
  50%{box-shadow:0 4px 30px rgba(239,68,68,0.7)}
}

.call-btn{
  background:linear-gradient(135deg,#22c55e,#16a34a);
  color:white;
  box-shadow:0 4px 20px rgba(34,197,94,0.3);
}
.call-btn:hover:not(:disabled){transform:scale(1.08)}
.call-btn.active{
  background:linear-gradient(135deg,#ef4444,#dc2626);
  box-shadow:0 4px 20px rgba(239,68,68,0.4);
}

.stop-btn{
  width:44px;height:44px;
  border-radius:50%;
  background:rgba(255,255,255,0.08);
  border:1px solid var(--border);
  color:var(--text-muted);
  font-size:16px;
  cursor:pointer;
  display:flex;align-items:center;justify-content:center;
  transition:all .2s;
}
.stop-btn:hover:not(:disabled){background:rgba(255,255,255,0.14);color:var(--text)}
.stop-btn:disabled{opacity:.3;cursor:not-allowed}

/* ========== Settings Drawer ========== */
.settings-toggle{
  position:absolute;
  top:16px;right:16px;
  background:none;border:none;
  color:var(--text-muted);
  font-size:18px;
  cursor:pointer;
  padding:6px;
  border-radius:8px;
  transition:all .2s;
}
.settings-toggle:hover{color:var(--text);background:rgba(255,255,255,0.06)}

.settings-drawer{
  display:none;
  position:fixed;
  top:0;right:0;bottom:0;
  width:300px;
  background:var(--bg-card);
  border-left:1px solid var(--border);
  backdrop-filter:blur(20px);
  padding:24px;
  z-index:100;
  flex-direction:column;
  gap:16px;
}
.settings-drawer.open{display:flex}
.settings-drawer h3{font-size:16px;margin-bottom:8px}
.settings-drawer label{
  display:block;font-size:12px;color:var(--text-muted);margin-bottom:4px;
}
.settings-drawer input,.settings-drawer select{
  width:100%;
  padding:8px 12px;
  background:rgba(255,255,255,0.06);
  border:1px solid var(--border);
  border-radius:8px;
  color:var(--text);
  font-size:13px;
}
.settings-drawer .close-btn{
  align-self:flex-end;
  background:none;border:none;color:var(--text-muted);
  font-size:20px;cursor:pointer;
}

/* ========== Responsive ========== */
@media(max-width:480px){
  .app{padding:8px 8px 0}
  .video-panel{height:160px}
  .action-btn{width:56px;height:56px;font-size:20px}
}
</style>
</head>

<body>
<div class="app">
  <button class="settings-toggle" onclick="toggleSettings()">&#9881;</button>

  <header class="header">
    <h1>MiniCPM-o 4.5</h1>
    <p>Lightweight local multimodal assistant</p>
  </header>

  <nav class="mode-tabs">
    <button class="mode-tab active" data-mode="voice" onclick="switchMode('voice')">
      <span>&#127908;</span> Voice Chat
    </button>
    <button class="mode-tab" data-mode="video" onclick="switchMode('video')">
      <span>&#128247;</span> Video Chat
    </button>
    <button class="mode-tab" data-mode="call" onclick="switchMode('call')">
      <span>&#128222;</span> Video Call
    </button>
  </nav>

  <main class="content">
    <section class="video-panel hidden" id="videoPanel">
      <video id="cameraPreview" autoplay playsinline muted></video>
      <canvas id="captureCanvas"></canvas>
      <div class="avatar" id="avatar">&#129302;</div>
    </section>

    <section class="chat-panel" id="chatPanel">
      <div class="msg system"><div class="msg-bubble">Click a mode tab to begin</div></div>
    </section>
  </main>

  <footer class="controls">
    <div class="status-bar" id="statusBar">Connecting...</div>
    <div class="btn-row">
      <button class="stop-btn" id="btnStop" disabled onclick="onStopClick()" title="Stop">&#9724;</button>
      <!-- Simplex mic button -->
      <button class="action-btn mic-btn" id="btnMic" disabled title="Hold to talk">&#127908;</button>
      <!-- Duplex call button -->
      <button class="action-btn call-btn" id="btnCall" style="display:none" disabled onclick="onCallClick()" title="Start call">&#128222;</button>
      <button class="stop-btn" id="btnBreak" disabled onclick="onBreakClick()" title="Interrupt">&#9208;</button>
    </div>
  </footer>
</div>

<!-- Settings Drawer -->
<div class="settings-drawer" id="settingsDrawer">
  <button class="close-btn" onclick="toggleSettings()">&times;</button>
  <h3>Settings</h3>
  <div>
    <label>Server URL</label>
    <input id="cfgServer" value="http://localhost:9060">
  </div>
  <div>
    <label>Language</label>
    <select id="cfgLang">
      <option value="zh" selected>Chinese</option>
      <option value="en">English</option>
    </select>
  </div>
  <div>
    <label>Duplex send interval (ms)</label>
    <input id="cfgInterval" type="number" value="1000" min="500" max="10000" step="500">
  </div>
</div>

<script>
/* ============================================================
   MiniCPM-o 4.5 Frontend
   
   Sections:
   1. CONFIG        - Constants and settings
   2. UTILS         - WAV encoding, base64, downsampling
   3. STATE         - Application state
   4. UI            - DOM helpers
   5. AUDIO_CAPTURE - Microphone recording
   6. VIDEO_CAPTURE - Camera frame capture
   7. AUDIO_PLAYER  - Queue-based PCM playback
   8. API           - Backend communication
   9. SIMPLEX       - Push-to-talk flow
   10. DUPLEX       - Continuous call flow
   11. EVENTS       - Event listeners
   12. INIT         - Startup
   ============================================================ */

// ==================== 1. CONFIG ====================

const CFG = {
  get serverUrl() { return document.getElementById('cfgServer').value.trim(); },
  get language() { return document.getElementById('cfgLang').value; },
  get sendIntervalMs() { return parseInt(document.getElementById('cfgInterval').value) || 2000; },
  TARGET_SAMPLE_RATE: 16000,
  PLAYBACK_SAMPLE_RATE: 24000,
};

// ==================== 2. UTILS ====================

/** Encode Float32Array PCM samples into a WAV ArrayBuffer (16-bit, mono) */
function encodeWAV(samples, sampleRate) {
  const numSamples = samples.length;
  const buffer = new ArrayBuffer(44 + numSamples * 2);
  const v = new DataView(buffer);

  function writeStr(offset, s) {
    for (let i = 0; i < s.length; i++) v.setUint8(offset + i, s.charCodeAt(i));
  }

  writeStr(0, 'RIFF');
  v.setUint32(4, 36 + numSamples * 2, true);
  writeStr(8, 'WAVE');
  writeStr(12, 'fmt ');
  v.setUint32(16, 16, true);       // fmt chunk size
  v.setUint16(20, 1, true);        // PCM
  v.setUint16(22, 1, true);        // mono
  v.setUint32(24, sampleRate, true);
  v.setUint32(28, sampleRate * 2, true); // byte rate
  v.setUint16(32, 2, true);        // block align
  v.setUint16(34, 16, true);       // bits per sample
  writeStr(36, 'data');
  v.setUint32(40, numSamples * 2, true);

  let offset = 44;
  for (let i = 0; i < numSamples; i++) {
    const s = Math.max(-1, Math.min(1, samples[i]));
    v.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
    offset += 2;
  }
  return buffer;
}

/** Downsample Float32Array using linear interpolation */
function downsample(buf, fromRate, toRate) {
  if (fromRate === toRate) return buf;
  const ratio = fromRate / toRate;
  const len = Math.round(buf.length / ratio);
  const out = new Float32Array(len);
  for (let i = 0; i < len; i++) {
    const idx = i * ratio;
    const lo = Math.floor(idx);
    const hi = Math.min(lo + 1, buf.length - 1);
    const f = idx - lo;
    out[i] = buf[lo] * (1 - f) + buf[hi] * f;
  }
  return out;
}

/** Convert ArrayBuffer to base64 string (chunked for large data) */
function arrayBufToBase64(buffer) {
  const bytes = new Uint8Array(buffer);
  let bin = '';
  const chunk = 8192;
  for (let i = 0; i < bytes.length; i += chunk) {
    bin += String.fromCharCode.apply(null, bytes.subarray(i, Math.min(i + chunk, bytes.length)));
  }
  return btoa(bin);
}

/** Merge array of Float32Arrays into one */
function mergeFloat32(arrays) {
  const total = arrays.reduce((s, a) => s + a.length, 0);
  const out = new Float32Array(total);
  let off = 0;
  for (const a of arrays) { out.set(a, off); off += a.length; }
  return out;
}

function sleep(ms) { return new Promise(r => setTimeout(r, ms)); }

// ==================== 3. STATE ====================

const S = {
  mode: 'voice',           // 'voice' | 'video' | 'call'
  phase: 'idle',           // 'idle' | 'ready' | 'recording' | 'processing' | 'in_call'
  sessionInited: false,

  // Audio capture
  audioCtx: null,
  micStream: null,
  scriptNode: null,
  capturedChunks: [],
  nativeSampleRate: 48000,
  micCapturing: false,

  // Video
  cameraStream: null,
  cameraActive: false,

  // Mic readiness (simplex: wait for mic before flush)
  micReadyPromise: null,

  // Duplex
  isInCall: false,
  sendLoopHandle: null,
  receiveAbort: null,

  // Playback
  playCtx: null,
  nextPlayTime: 0,
  playingSources: [],

  // Generation
  generating: false,
  generatingAbort: null,
};

// ==================== 4. UI ====================

const $chat = document.getElementById('chatPanel');
const $status = document.getElementById('statusBar');
const $videoPanel = document.getElementById('videoPanel');
const $video = document.getElementById('cameraPreview');
const $canvas = document.getElementById('captureCanvas');
const $avatar = document.getElementById('avatar');
const $btnMic = document.getElementById('btnMic');
const $btnCall = document.getElementById('btnCall');
const $btnStop = document.getElementById('btnStop');
const $btnBreak = document.getElementById('btnBreak');

function setStatus(text, cls = '') {
  $status.textContent = text;
  $status.className = 'status-bar' + (cls ? ' ' + cls : '');
}

function addMsg(text, role = 'system') {
  const d = document.createElement('div');
  d.className = 'msg ' + role;
  const b = document.createElement('div');
  b.className = 'msg-bubble';
  b.textContent = text;
  d.appendChild(b);
  $chat.appendChild(d);
  $chat.scrollTop = $chat.scrollHeight;
  return b;
}

/** Create or get the current streaming assistant bubble */
let _streamBubble = null;
function getStreamBubble() {
  if (!_streamBubble) {
    _streamBubble = addMsg('', 'assistant');
    _streamBubble.classList.add('msg-text-streaming');
  }
  return _streamBubble;
}
function appendStreamText(text) {
  const b = getStreamBubble();
  b.textContent += text;
  $chat.scrollTop = $chat.scrollHeight;
}
function finalizeStreamBubble() {
  if (_streamBubble) {
    _streamBubble.classList.remove('msg-text-streaming');
    if (!_streamBubble.textContent.trim()) {
      _streamBubble.parentElement.remove();
    }
    _streamBubble = null;
  }
}

function updateModeUI() {
  document.querySelectorAll('.mode-tab').forEach(t => {
    t.classList.toggle('active', t.dataset.mode === S.mode);
  });

  const showVideo = (S.mode === 'video' || S.mode === 'call');
  $videoPanel.classList.toggle('hidden', !showVideo);
  $video.style.display = showVideo && S.cameraActive ? 'block' : 'none';
  $avatar.style.display = showVideo && S.cameraActive ? 'none' : 'flex';

  const isDuplex = (S.mode === 'call');
  $btnMic.style.display = isDuplex ? 'none' : 'flex';
  $btnCall.style.display = isDuplex ? 'flex' : 'none';
}

function updateControlStates() {
  const ready = S.sessionInited && S.phase === 'ready';
  $btnMic.disabled = !ready;
  $btnCall.disabled = !(S.sessionInited && (S.phase === 'ready' || S.phase === 'in_call'));
  $btnStop.disabled = !S.generating && S.phase !== 'in_call';
  $btnBreak.disabled = !S.generating;

  $btnCall.classList.toggle('active', S.phase === 'in_call');
  $btnCall.innerHTML = S.phase === 'in_call' ? '&#128308;' : '&#128222;';
}

function toggleSettings() {
  document.getElementById('settingsDrawer').classList.toggle('open');
}

// ==================== 5. AUDIO CAPTURE ====================

async function startMicCapture() {
  // 复用已有的 AudioContext 和 mic stream（避免反复创建/销毁导致设备冲突）
  if (S.scriptNode) {
    // 已经在录音中，只需清空 buffer
    S.capturedChunks = [];
    S.micCapturing = true;
    return;
  }

  if (!S.micStream || !S.micStream.active) {
    S.micStream = await navigator.mediaDevices.getUserMedia({
      audio: { channelCount: 1, echoCancellation: true, noiseSuppression: true }
    });
  }

  if (!S.audioCtx || S.audioCtx.state === 'closed') {
    S.audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    S.nativeSampleRate = S.audioCtx.sampleRate;
  }
  if (S.audioCtx.state === 'suspended') {
    await S.audioCtx.resume();
  }

  const source = S.audioCtx.createMediaStreamSource(S.micStream);

  // Use ScriptProcessorNode (widely supported; fine for local demo)
  S.scriptNode = S.audioCtx.createScriptProcessor(4096, 1, 1);
  S.capturedChunks = [];
  S.micCapturing = true;

  S.scriptNode.onaudioprocess = (e) => {
    if (!S.micCapturing) return; // gate: 只在录音时采集
    const data = e.inputBuffer.getChannelData(0);
    S.capturedChunks.push(new Float32Array(data));
  };

  source.connect(S.scriptNode);
  // ScriptProcessorNode 必须连接到 destination 才会触发 onaudioprocess，
  // 但用静音 GainNode 避免麦克风音频送入扬声器（防反馈 + 防设备冲突）
  const silentGain = S.audioCtx.createGain();
  silentGain.gain.value = 0;
  S.scriptNode.connect(silentGain);
  silentGain.connect(S.audioCtx.destination);
}

function stopMicCapture() {
  // simplex 模式：暂停采集但不销毁 AudioContext（避免设备冲突）
  S.micCapturing = false;
}

/** 完全释放麦克风和 AudioContext（切换模式/退出时调用） */
function destroyMicCapture() {
  S.micCapturing = false;
  if (S.scriptNode) { S.scriptNode.disconnect(); S.scriptNode = null; }
  if (S.audioCtx) { S.audioCtx.close().catch(() => {}); S.audioCtx = null; }
  if (S.micStream) { S.micStream.getTracks().forEach(t => t.stop()); S.micStream = null; }
}

/** Flush captured audio: merge, downsample to 16kHz, return Float32Array */
function flushAudio() {
  if (S.capturedChunks.length === 0) return null;
  const merged = mergeFloat32(S.capturedChunks);
  S.capturedChunks = [];
  if (merged.length < 160) return null; // too short (<10ms)
  return downsample(merged, S.nativeSampleRate, CFG.TARGET_SAMPLE_RATE);
}

/** Encode flushed audio to base64 WAV */
function audioToBase64(samples) {
  const wavBuf = encodeWAV(samples, CFG.TARGET_SAMPLE_RATE);
  return arrayBufToBase64(wavBuf);
}

// ==================== 6. VIDEO CAPTURE ====================

async function startCamera() {
  if (S.cameraActive) return;
  try {
    S.cameraStream = await navigator.mediaDevices.getUserMedia({
      video: { facingMode: 'user', width: { ideal: 640 }, height: { ideal: 480 } }
    });
    $video.srcObject = S.cameraStream;
    S.cameraActive = true;
    $video.style.display = 'block';
    $avatar.style.display = 'none';
  } catch (e) {
    console.warn('Camera unavailable:', e);
    S.cameraActive = false;
  }
}

function stopCamera() {
  if (S.cameraStream) {
    S.cameraStream.getTracks().forEach(t => t.stop());
    S.cameraStream = null;
  }
  $video.srcObject = null;
  S.cameraActive = false;
  $video.style.display = 'none';
  $avatar.style.display = 'flex';
}

/** Capture current video frame as base64 JPEG (or null if no camera) */
function captureFrame() {
  if (!S.cameraActive || !$video.videoWidth) return null;
  $canvas.width = Math.min($video.videoWidth, 640);
  $canvas.height = Math.min($video.videoHeight, 480);
  const ctx = $canvas.getContext('2d');
  ctx.drawImage($video, 0, 0, $canvas.width, $canvas.height);
  const dataUrl = $canvas.toDataURL('image/jpeg', 0.7);
  return dataUrl.split(',')[1]; // base64 part only
}

// ==================== 7. AUDIO PLAYER ====================

function ensurePlayCtx() {
  if (!S.playCtx || S.playCtx.state === 'closed') {
    S.playCtx = new (window.AudioContext || window.webkitAudioContext)();
    S.nextPlayTime = 0;
  }
  // 浏览器安全策略：AudioContext 创建后可能处于 suspended 状态，必须 resume
  // resume() 返回 Promise，但无需 await —— 已调度的 source 会在 resume 完成后自动播放
  if (S.playCtx.state === 'suspended') {
    S.playCtx.resume().catch(() => {});
  }
}

/** Enqueue a PCM int16 base64 chunk for gapless playback */
function enqueueAudio(base64Pcm, sampleRate) {
  ensurePlayCtx();
  try {
    const bin = atob(base64Pcm);
    const bytes = new Uint8Array(bin.length);
    for (let i = 0; i < bin.length; i++) bytes[i] = bin.charCodeAt(i);
    const int16 = new Int16Array(bytes.buffer);
    const float32 = new Float32Array(int16.length);
    for (let i = 0; i < int16.length; i++) float32[i] = int16[i] / 32768.0;

    const sr = sampleRate || CFG.PLAYBACK_SAMPLE_RATE;
    const buf = S.playCtx.createBuffer(1, float32.length, sr);
    buf.getChannelData(0).set(float32);

    const source = S.playCtx.createBufferSource();
    source.buffer = buf;
    source.connect(S.playCtx.destination);

    const now = S.playCtx.currentTime;
    const start = Math.max(now + 0.02, S.nextPlayTime);
    source.start(start);
    S.nextPlayTime = start + buf.duration;
    S.playingSources.push(source);

    source.onended = () => {
      const idx = S.playingSources.indexOf(source);
      if (idx >= 0) S.playingSources.splice(idx, 1);
    };
  } catch (e) {
    console.error('Audio playback error:', e);
  }
}

function stopPlayback() {
  S.playingSources.forEach(s => { try { s.stop(); } catch(_) {} });
  S.playingSources = [];
  S.nextPlayTime = 0;
}

// ==================== 8. API ====================

async function apiInit(mediaType, duplexMode) {
  const resp = await fetch(`${CFG.serverUrl}/omni/init_sys_prompt`, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      media_type: mediaType,
      duplex_mode: duplexMode,
      language: CFG.language,
    }),
  });
  if (!resp.ok) throw new Error(`Init failed: ${resp.status} ${await resp.text()}`);
  return resp.json();
}

async function apiPrefill(audioB64, imageB64) {
  const body = {};
  if (audioB64) body.audio = audioB64;
  if (imageB64) body.image = imageB64;
  const resp = await fetch(`${CFG.serverUrl}/omni/streaming_prefill`, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify(body),
  });
  if (!resp.ok) throw new Error(`Prefill failed: ${resp.status}`);
  return resp.json();
}

/**
 * Call streaming_generate and process SSE events.
 * 
 * @param {Function} onChunk  - Called with {wav, sample_rate, text} for each audio chunk
 * @param {Function} onDone   - Called when generation finishes
 * @param {AbortSignal} signal - For cancellation
 * @returns {Promise<{isListen: boolean}>}
 */
async function apiGenerate(onChunk, onDone, signal) {
  const resp = await fetch(`${CFG.serverUrl}/omni/streaming_generate`, {
    method: 'POST',
    headers: { 'Accept': 'text/event-stream' },
    signal,
  });
  if (!resp.ok) throw new Error(`Generate failed: ${resp.status}`);

  const reader = resp.body.getReader();
  const decoder = new TextDecoder();
  let buffer = '';
  let isListen = false;

  while (true) {
    const { done, value } = await reader.read();
    if (done) break;
    buffer += decoder.decode(value, { stream: true });

    // Split on double newlines (SSE event boundaries)
    let idx;
    while ((idx = buffer.indexOf('\n\n')) >= 0) {
      const eventBlock = buffer.substring(0, idx);
      buffer = buffer.substring(idx + 2);

      for (const line of eventBlock.split('\n')) {
        if (!line.startsWith('data: ')) continue;
        try {
          const data = JSON.parse(line.substring(6));

          if (data.chunk_data) {
            onChunk(data.chunk_data);
          }
          // Backend sends {break: true, done: true} on user interrupt
          if (data.break) {
            onDone();
            return { isListen: false };
          }
          // Backend duplex final event: {done: true, is_listen: bool}
          // Backend simplex final event: {done: true}
          if (data.done) {
            onDone();
            return { isListen: !!data.is_listen };
          }
        } catch (_) {}
      }
    }
  }
  onDone();
  return { isListen };
}

async function apiStop() {
  try {
    await fetch(`${CFG.serverUrl}/omni/stop`, { method: 'POST' });
  } catch (_) {}
}

async function apiBreak() {
  try {
    await fetch(`${CFG.serverUrl}/omni/break`, { method: 'POST' });
  } catch (_) {}
}

async function apiHealth() {
  const resp = await fetch(`${CFG.serverUrl}/health`);
  return resp.ok;
}

// ==================== 9. SIMPLEX FLOW ====================

async function simplexInit() {
  const mediaType = S.mode === 'voice' ? 'audio' : 'omni';
  setStatus('Initializing...', 'active');
  try {
    await apiInit(mediaType, false);
    S.sessionInited = true;
    S.phase = 'ready';
    setStatus('Ready - hold mic to talk', 'ok');
    addMsg('Session initialized (' + (S.mode === 'voice' ? 'Voice' : 'Video') + ' mode)', 'system');
    if (S.mode === 'video') await startCamera();
  } catch (e) {
    setStatus('Init failed: ' + e.message, 'err');
    addMsg('Error: ' + e.message, 'system');
  }
  updateControlStates();
}

async function simplexStartRecording() {
  if (S.phase !== 'ready') return;
  S.phase = 'recording';
  setStatus('Recording...', 'warn');
  $btnMic.classList.add('recording');
  $btnMic.innerHTML = '&#9724;';
  updateControlStates();

  // 保存 mic 初始化 promise，让 stopRecording 可以等待它完成
  S.micReadyPromise = startMicCapture().catch((e) => {
    setStatus('Mic access denied', 'err');
    S.phase = 'ready';
    $btnMic.classList.remove('recording');
    $btnMic.innerHTML = '&#127908;';
    updateControlStates();
    throw e;
  });

  try {
    await S.micReadyPromise;
  } catch (_) {}
}

async function simplexStopRecording() {
  if (S.phase !== 'recording') return;
  S.phase = 'processing';
  $btnMic.classList.remove('recording');
  $btnMic.innerHTML = '&#127908;';
  setStatus('Processing...', 'active');
  updateControlStates();

  // 等待麦克风初始化完成（用户可能在 mic 还没就绪时就松手了）
  if (S.micReadyPromise) {
    try { await S.micReadyPromise; } catch (_) {
      S.phase = 'ready';
      updateControlStates();
      return;
    }
    S.micReadyPromise = null;
  }

  // Flush captured audio
  const audioSamples = flushAudio();
  stopMicCapture();

  if (!audioSamples || audioSamples.length < 1600) {
    setStatus('Recording too short, try again', 'warn');
    S.phase = 'ready';
    updateControlStates();
    return;
  }

  const audioB64 = audioToBase64(audioSamples);
  const imageB64 = (S.mode === 'video') ? captureFrame() : null;

  addMsg(imageB64 ? '[Voice + Video]' : '[Voice message]', 'user');

  try {
    // Prefill
    setStatus('Sending to model...', 'active');
    await apiPrefill(audioB64, imageB64);

    // Generate
    S.generating = true;
    updateControlStates();
    setStatus('Generating response...', 'active');
    stopPlayback();

    const abort = new AbortController();
    S.generatingAbort = abort;

    await apiGenerate(
      (chunk) => {
        if (chunk.wav) enqueueAudio(chunk.wav, chunk.sample_rate);
        if (chunk.text) appendStreamText(chunk.text);
      },
      () => {
        finalizeStreamBubble();
        S.generating = false;
        S.generatingAbort = null;
        S.phase = 'ready';
        setStatus('Ready - hold mic to talk', 'ok');
        updateControlStates();
      },
      abort.signal
    );
  } catch (e) {
    if (e.name === 'AbortError') {
      setStatus('Stopped', 'warn');
    } else {
      setStatus('Error: ' + e.message, 'err');
      addMsg('Error: ' + e.message, 'system');
    }
    finalizeStreamBubble();
    S.generating = false;
    S.generatingAbort = null;
    S.phase = 'ready';
    updateControlStates();
  }
}

// ==================== 10. DUPLEX FLOW ====================

async function duplexStart() {
  if (S.phase === 'in_call') { duplexStop(); return; }

  setStatus('Starting call...', 'active');
  S.phase = 'in_call';
  S.isInCall = true;
  updateControlStates();
  updateModeUI();

  try {
    await apiInit('omni', true);
    S.sessionInited = true;
    addMsg('Video call started (Duplex mode)', 'system');

    await startCamera();
    await startMicCapture();

    setStatus('In call', 'ok');
    updateControlStates();

    // Start send & receive loops concurrently
    duplexSendLoop();
    duplexReceiveLoop();
  } catch (e) {
    setStatus('Call failed: ' + e.message, 'err');
    addMsg('Error: ' + e.message, 'system');
    duplexCleanup();
  }
}

async function duplexSendLoop() {
  while (S.isInCall) {
    await sleep(CFG.sendIntervalMs);
    if (!S.isInCall) break;

    const audioSamples = flushAudio();
    if (!audioSamples || audioSamples.length < 800) continue;

    const audioB64 = audioToBase64(audioSamples);
    const imageB64 = captureFrame();

    try {
      await apiPrefill(audioB64, imageB64);
    } catch (e) {
      console.warn('Prefill error in duplex send:', e);
    }
  }
}

async function duplexReceiveLoop() {
  while (S.isInCall) {
    try {
      const abort = new AbortController();
      S.receiveAbort = abort;
      S.generating = true;
      updateControlStates();

      const result = await apiGenerate(
        (chunk) => {
          if (chunk.wav) enqueueAudio(chunk.wav, chunk.sample_rate);
          if (chunk.text) appendStreamText(chunk.text);
          $avatar.classList.add('speaking');
        },
        () => {
          finalizeStreamBubble();
          $avatar.classList.remove('speaking');
          S.generating = false;
          updateControlStates();
        },
        abort.signal
      );

      // If is_listen, loop back for next round
      if (result.isListen && S.isInCall) {
        await sleep(100);
        continue;
      }
      // Otherwise, the call has ended or error occurred
      break;
    } catch (e) {
      if (e.name === 'AbortError') break;
      console.warn('Generate error in duplex receive:', e);
      if (S.isInCall) await sleep(1000); // retry after delay
    }
  }
}

function duplexStop() {
  S.isInCall = false;
  if (S.receiveAbort) { S.receiveAbort.abort(); S.receiveAbort = null; }
  apiStop().catch(() => {});
  duplexCleanup();
  addMsg('Call ended', 'system');
  setStatus('Ready', 'ok');
}

function duplexCleanup() {
  S.isInCall = false;
  S.generating = false;
  S.phase = 'ready';
  destroyMicCapture();
  stopPlayback();
  finalizeStreamBubble();
  $avatar.classList.remove('speaking');
  updateControlStates();
}

// ==================== 11. EVENT HANDLERS ====================

async function switchMode(mode) {
  // 用户点击模式切换时，预热播放 AudioContext（浏览器要求用户手势才能 resume）
  ensurePlayCtx();

  // Cleanup previous mode
  if (S.phase === 'in_call') duplexStop();
  destroyMicCapture(); // 切换模式时完全释放麦克风和 AudioContext
  stopPlayback();
  finalizeStreamBubble();

  // Stop camera if switching away from video modes
  if ((mode === 'voice') && S.cameraActive) stopCamera();

  S.mode = mode;
  S.phase = 'idle';
  S.sessionInited = false;
  S.generating = false;
  updateModeUI();
  updateControlStates();

  // Auto-init session
  if (mode === 'call') {
    // Duplex: init happens on call start
    setStatus('Press call button to start', 'ok');
    S.phase = 'ready';
    S.sessionInited = true; // will re-init on call
    updateControlStates();
  } else {
    await simplexInit();
  }
}

function onStopClick() {
  if (S.phase === 'in_call') {
    duplexStop();
  } else if (S.generating && S.generatingAbort) {
    S.generatingAbort.abort();
    apiStop();
    stopPlayback();
  }
}

function onBreakClick() {
  if (S.generating) {
    apiBreak();
  }
}

function onCallClick() {
  ensurePlayCtx(); // 预热播放 AudioContext（用户手势内调用才能 resume）
  if (S.phase === 'in_call') {
    duplexStop();
  } else {
    duplexStart();
  }
}

// Mic button: press-and-hold for simplex
let micPressing = false;

function micDown() {
  if (S.mode === 'call' || S.phase !== 'ready') return;
  micPressing = true;
  ensurePlayCtx(); // 预热播放 AudioContext（用户手势内调用才能 resume）
  simplexStartRecording();
}

function micUp() {
  if (!micPressing) return;
  micPressing = false;
  if (S.phase === 'recording') simplexStopRecording();
}

$btnMic.addEventListener('mousedown', micDown);
$btnMic.addEventListener('mouseup', micUp);
$btnMic.addEventListener('mouseleave', micUp);
$btnMic.addEventListener('touchstart', (e) => { e.preventDefault(); micDown(); });
$btnMic.addEventListener('touchend', (e) => { e.preventDefault(); micUp(); });

// Keyboard shortcut: Space to record
document.addEventListener('keydown', (e) => {
  if (e.code === 'Space' && !e.repeat && S.mode !== 'call' && S.phase === 'ready' && document.activeElement.tagName !== 'INPUT') {
    e.preventDefault();
    micDown();
  }
});
document.addEventListener('keyup', (e) => {
  if (e.code === 'Space') {
    e.preventDefault();
    micUp();
  }
});

// ==================== 12. INIT ====================

(async function init() {
  updateModeUI();
  updateControlStates();
  setStatus('Checking server...', 'active');

  try {
    const ok = await apiHealth();
    if (ok) {
      setStatus('Server connected', 'ok');
      // Auto-init voice mode
      await simplexInit();
    } else {
      setStatus('Server not ready', 'warn');
    }
  } catch (e) {
    setStatus('Cannot reach server at ' + CFG.serverUrl, 'err');
    addMsg('Please start the server first: python server.py', 'system');
  }
})();
</script>
</body>
</html>
